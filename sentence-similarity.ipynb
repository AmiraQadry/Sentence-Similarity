{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4550791,"sourceType":"datasetVersion","datasetId":2656775}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:26:18.939186Z","iopub.execute_input":"2024-07-30T11:26:18.939904Z","iopub.status.idle":"2024-07-30T11:26:22.603315Z","shell.execute_reply.started":"2024-07-30T11:26:18.939867Z","shell.execute_reply":"2024-07-30T11:26:22.602549Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\ndata = pd.read_csv(\"/kaggle/input/nli-dataset-for-sentence-understanding/sst2_train.csv\")\n\n# Display the first few rows\nprint(data.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:26:22.605051Z","iopub.execute_input":"2024-07-30T11:26:22.605870Z","iopub.status.idle":"2024-07-30T11:26:22.697063Z","shell.execute_reply.started":"2024-07-30T11:26:22.605834Z","shell.execute_reply":"2024-07-30T11:26:22.696211Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"                                            sentence  label  idx\n0       hide new secretions from the parental units       0    0\n1               contains no wit , only labored gags       0    1\n2  that loves its characters and communicates som...      1    2\n3  remains utterly satisfied to remain the same t...      0    3\n4  on the worst revenge-of-the-nerds clichés the ...      0    4\n","output_type":"stream"}]},{"cell_type":"code","source":"# Download NLTK data\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:26:32.891526Z","iopub.execute_input":"2024-07-30T11:26:32.892372Z","iopub.status.idle":"2024-07-30T11:26:32.972534Z","shell.execute_reply.started":"2024-07-30T11:26:32.892335Z","shell.execute_reply":"2024-07-30T11:26:32.971681Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Define preprocessing function\ndef preprocess_text(text):\n    tokens = word_tokenize(text)\n    tokens = [word.lower() for word in tokens]\n    tokens = [word for word in tokens if word.isalnum()]\n    stop_words = set(stopwords.words('english'))\n    tokens = [word for word in tokens if word not in stop_words]\n    return ' '.join(tokens)\n\n# Apply preprocessing\ndata['sentence'] = data['sentence'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:27:15.256539Z","iopub.execute_input":"2024-07-30T11:27:15.257276Z","iopub.status.idle":"2024-07-30T11:27:36.819960Z","shell.execute_reply.started":"2024-07-30T11:27:15.257244Z","shell.execute_reply":"2024-07-30T11:27:36.819157Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained BERT model and tokenizer\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased').to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:28:00.489365Z","iopub.execute_input":"2024-07-30T11:28:00.489987Z","iopub.status.idle":"2024-07-30T11:28:01.628410Z","shell.execute_reply.started":"2024-07-30T11:28:00.489956Z","shell.execute_reply":"2024-07-30T11:28:01.627352Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Function to get sentence embeddings\ndef get_sentence_embedding(sentences):\n    inputs = tokenizer(sentences, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n    return embeddings\n\n# Batch processing\nbatch_size = 32\nembeddings = []\nfor i in tqdm(range(0, len(data), batch_size)):\n    batch_sentences = data['sentence'][i:i+batch_size].tolist()\n    batch_embeddings = get_sentence_embedding(batch_sentences)\n    embeddings.extend(batch_embeddings)\n\ndata['embedding'] = embeddings","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:28:03.368135Z","iopub.execute_input":"2024-07-30T11:28:03.368905Z","iopub.status.idle":"2024-07-30T11:29:37.572000Z","shell.execute_reply.started":"2024-07-30T11:28:03.368871Z","shell.execute_reply":"2024-07-30T11:29:37.570978Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 2105/2105 [01:34<00:00, 22.35it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ensure embeddings column is not empty\ndata = data.dropna(subset=['embedding'])","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:32:07.137097Z","iopub.execute_input":"2024-07-30T11:32:07.138180Z","iopub.status.idle":"2024-07-30T11:32:07.171214Z","shell.execute_reply.started":"2024-07-30T11:32:07.138132Z","shell.execute_reply":"2024-07-30T11:32:07.170149Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# For simplicity, we'll pair each sentence with the next one in the dataset\n# Create a new DataFrame to store pairs of sentences and their embeddings\npaired_data = pd.DataFrame({\n    'sentence1': data['sentence'][:-1],\n    'sentence2': data['sentence'][1:],\n    'embedding1': data['embedding'][:-1],\n    'embedding2': data['embedding'][1:]\n})","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:32:13.033199Z","iopub.execute_input":"2024-07-30T11:32:13.033573Z","iopub.status.idle":"2024-07-30T11:32:13.054903Z","shell.execute_reply.started":"2024-07-30T11:32:13.033542Z","shell.execute_reply":"2024-07-30T11:32:13.054120Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Ensure embeddings are numpy arrays\npaired_data = paired_data.dropna(subset=['embedding1', 'embedding2'])","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:32:36.824075Z","iopub.execute_input":"2024-07-30T11:32:36.824454Z","iopub.status.idle":"2024-07-30T11:32:36.854117Z","shell.execute_reply.started":"2024-07-30T11:32:36.824424Z","shell.execute_reply":"2024-07-30T11:32:36.853029Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Function to compute cosine similarity\ndef compute_cosine_similarity(embedding1, embedding2):\n    return cosine_similarity([embedding1], [embedding2])[0][0]\n\n# Compute cosine similarity for each pair of sentences\npaired_data['similarity'] = paired_data.apply(lambda row: compute_cosine_similarity(row['embedding1'], row['embedding2']), axis=1)\n\n# Display the first few rows with similarity scores\nprint(paired_data.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:32:47.769288Z","iopub.execute_input":"2024-07-30T11:32:47.770018Z","iopub.status.idle":"2024-07-30T11:33:07.927455Z","shell.execute_reply.started":"2024-07-30T11:32:47.769983Z","shell.execute_reply":"2024-07-30T11:33:07.926481Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"                                           sentence1  \\\n1                          contains wit labored gags   \n2  loves characters communicates something rather...   \n3        remains utterly satisfied remain throughout   \n4              worst clichés filmmakers could dredge   \n5             far tragic merit superficial treatment   \n\n                                           sentence2  \\\n1                          contains wit labored gags   \n2  loves characters communicates something rather...   \n3        remains utterly satisfied remain throughout   \n4              worst clichés filmmakers could dredge   \n5             far tragic merit superficial treatment   \n\n                                          embedding1  \\\n1  [-0.40373817, -0.14012745, -0.3527661, 0.20648...   \n2  [-0.33055326, 0.2092333, -0.09828734, -0.27186...   \n3  [-0.50376976, 0.08698111, 0.13549073, -0.36353...   \n4  [0.035091516, 0.5224591, -0.08824775, 0.159987...   \n5  [-0.2025517, 0.11368114, -0.07959042, -0.04298...   \n\n                                          embedding2  similarity  \n1  [-0.40373817, -0.14012745, -0.3527661, 0.20648...         1.0  \n2  [-0.33055326, 0.2092333, -0.09828734, -0.27186...         1.0  \n3  [-0.50376976, 0.08698111, 0.13549073, -0.36353...         1.0  \n4  [0.035091516, 0.5224591, -0.08824775, 0.159987...         1.0  \n5  [-0.2025517, 0.11368114, -0.07959042, -0.04298...         1.0  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming we don't have a ground truth similarity column, we'll skip the evaluation step\n# If we had a true similarity score, we could use mean_squared_error or another metric for evaluation\n\n# Function to get similarity between two new sentences\ndef get_similarity(sentence1, sentence2):\n    embedding1 = get_sentence_embedding([sentence1])[0]\n    embedding2 = get_sentence_embedding([sentence2])[0]\n    similarity = compute_cosine_similarity(embedding1, embedding2)\n    return similarity\n\n# Example usage\nsentence1 = \"This is an example sentence.\"\nsentence2 = \"This is another example sentence.\"\nsimilarity_score = get_similarity(sentence1, sentence2)\nprint(f'Similarity Score: {similarity_score}')","metadata":{"execution":{"iopub.status.busy":"2024-07-30T11:33:23.016718Z","iopub.execute_input":"2024-07-30T11:33:23.017102Z","iopub.status.idle":"2024-07-30T11:33:23.070389Z","shell.execute_reply.started":"2024-07-30T11:33:23.017074Z","shell.execute_reply":"2024-07-30T11:33:23.069465Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Similarity Score: 0.9913215041160583\n","output_type":"stream"}]}]}